# -*- coding: utf-8 -*-
"""CSC606_Course_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15KmoAwNpoy8YpFGRLD8ab-BOdNWeZ9v0

#README
All code contained for this project was created and tested in Google Colab, which runs a similar environment as Jupyter Notebook. The code was developed in different cells to deliniate what was going on in each cell. I would suggest thast anyone wanting to run this code should consider running everything in Google Colab as well for simplicity's sake. The code will be downloaded in a .py format, which can be easily imported into google colab and then each cell should be run from top to bottom. Some cells contain data that is defined in higher level cells, so it is important to ensure no errors present values not being defined before hand. Outside of running each cell from top to botto in Colab, there should be no issues with running the code. Jupyter notebook will likely also work fine so long that the cells are deliniated as well upon importing.Thank you for your time.
"""

from os import sep
import pandas as pd
from google.colab import drive
from fastai.tabular.all import df_shrink


# drive.mount('/content/drive', force_remount=True) #used to call in the data set from my google drive.
file_path = "/content/drive/MyDrive/KDDTrain+.txt"
test_file_path = "/content/drive/MyDrive/KDDTest+.txt"
df = pd.read_csv(file_path, sep = ',', encoding='utf-8')
df_test = pd.read_csv(test_file_path, sep = ",", encoding='utf-8')
df.drop_duplicates(keep='first') #removes any duplicates in the data set
df_test.drop_duplicates(keep='first') #removes any duplicates in the data set
any_dupes = df.isnull().values.any() #determines if there are any missing values in the data set and returns True if there are any, false indicates no missing values
# print(any_dupes)

#Data set distribution of normal and total number of attacks is comparatively similar, with 54% of data being normal and 46% being attacks, so no need to remove extra normals to reduce bias risk, should already be reduced
#print(df['class'].value_counts()) #returns all different values of column 'class', which is the type of attacks in the training set and the number of each
df = df_shrink(df, skip=[], obj2cat=True, int2uint=True)
df_test = df_shrink(df_test, skip=[], obj2cat=True, int2uint=True)

#Random Forest Training
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd


X = df.iloc[:, ~df.columns.isin(['class', 'classnum'])] #define features, exclude 'class' and 'classnum'
Y = df[['class', 'classnum']] #define target variable including 'class' and 'classnum'
X_test = df_test.iloc[:, ~df_test.columns.isin(['class', 'classnum'])] #define features, exclude 'class' and 'classnum'
Y_test = df_test[['class', 'classnum']] #define target variable including 'class' and 'classnum'

#Convert categorical features to numerical using one-hot encoding
X = pd.get_dummies(X, columns=['protocol_type', 'service', 'flag'], drop_first=True)
X_test = pd.get_dummies(X_test, columns=['protocol_type', 'service', 'flag'], drop_first=True)


x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=None, random_state=42)

#Align columns - crucial for consistent feature sets
X_test = X_test.reindex(columns=x_train.columns, fill_value=0)

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)


classifier = RandomForestClassifier(n_estimators=500, max_features="sqrt")
classifier.fit(x_train_scaled, y_train['class']) #Fit using the 'class' column for Random Forest
y_prediction = classifier.predict(x_test_scaled)

accuracy = accuracy_score(y_test['class'], y_prediction) #Calculate accuracy using the 'class' column
print(f'Accuracy: {accuracy * 100:.2f}%')

conf_matrix = confusion_matrix(y_test['class'], y_prediction) #Use 'class' column for confusion matrix

#Visualizing model
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Purples', cbar=False)
plt.title("Confusion Matrix Heatmap of Attack Data")
plt.xlabel("Predicted values")
plt.ylabel("Actual values")
plt.show()

#Feature Importance for Hypertuning
feature_importances = classifier.feature_importances_

plt.barh(x_train.columns[0:30], feature_importances[0:30])
plt.xlabel("Random Forest Feature Importance 1-31")
plt.ylabel("Features")
plt.show()


plt.barh(x_train.columns[31:60], feature_importances[31:60])
plt.xlabel("Random Forest Feature Importance 32-61")
plt.ylabel("Features")
plt.show()

plt.barh(x_train.columns[61:90], feature_importances[61:90])
plt.xlabel("Random Forest Feature Importance 62-91")
plt.ylabel("Features")
plt.show()
plt.barh(x_train.columns[91:119], feature_importances[91:119])
plt.xlabel("Random Forest Feature Importance 92-120")
plt.ylabel("Features")
plt.show()

#Average of 72.25% accuracy without hypertuning
#Scaled data and now 99.8% accuracy

#Retrain model based on hypertuned parameters
X_best_params = df[["src_bytes","dst_bytes","count", "srv_count","serror_rate", "srv_serror_rate","same_srv_rate","diff_srv_rate","dst_host_count", "dst_host_srv_count",  "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", "dst_host_serror_rate","dst_host_serror_rate", "dst_host_srv_serror_rate", "dst_host_rerror_rate"]]
X_test_best_params = df_test[["src_bytes","dst_bytes","count", "srv_count","serror_rate", "srv_serror_rate","same_srv_rate","diff_srv_rate","dst_host_count", "dst_host_srv_count",  "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", "dst_host_serror_rate","dst_host_serror_rate", "dst_host_srv_serror_rate", "dst_host_rerror_rate"]]
Y_best_params = df[["class", "classnum"]]
Y_test_best_params = df_test[["class", "classnum"]]

scaler = StandardScaler()
x_train_scaled_best = scaler.fit_transform(X_best_params)
x_test_scaled_best = scaler.transform(X_test_best_params)

x_train_best, x_test_best, y_train_best, y_test_best = train_test_split(x_train_scaled_best, Y_best_params, test_size=None, random_state=42)


classifier_best_params = RandomForestClassifier(n_estimators=1000, max_features='sqrt', criterion='entropy')
classifier_best_params.fit(x_train_best, y_train_best['class']) #Fit using the 'class' column for Random Forest
y_prediction_best = classifier_best_params.predict(x_test_best)

accuracy_new = accuracy_score(y_test_best['class'], y_prediction_best) #Calculate accuracy using the 'class' column
print(f'New Accuracy: {accuracy_new * 100:.2f}%')

conf_matrix_new = confusion_matrix(y_test_best['class'], y_prediction_best) #Use 'class' column for confusion matrix

from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Use the numerical 'classnum' column as the target variable
y_train_scaled = y_train['classnum'].values.ravel()
y_test_scaled = y_test['classnum'].values.ravel()


rbf_svc_model = SVC(kernel='rbf', C=1e-3, gamma='scale')

# Train the model
rbf_svc_model.fit(x_train_scaled, y_train_scaled)
y_pred_ovr = rbf_svc_model.predict(x_test_scaled)

accuracy_svm = accuracy_score(y_test_scaled, y_pred_ovr)
print(f'Accuracy: {accuracy_svm * 100:.2f}%')

conf_matrix_svm = confusion_matrix(y_test_scaled, y_pred_ovr)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_svm, annot=True, fmt='g', cmap='Purples', cbar=False)
plt.title("Confusion Matrix Heatmap of Attack Data (SVM)")
plt.xlabel("Predicted values")
plt.ylabel("Actual values")
plt.show()

#With C=1e-3, accuracy = 66.57%, 5 minutes to train
#With C=1.0, accuracy = 66.98%, 30 minutes to train

#Hypertuned SVC Classifier
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

X_svc = df[["src_bytes","dst_bytes","count", "srv_count","serror_rate", "srv_serror_rate","same_srv_rate","diff_srv_rate","dst_host_count", "dst_host_srv_count",  "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", "dst_host_serror_rate","dst_host_serror_rate", "dst_host_srv_serror_rate", "dst_host_rerror_rate"]]
X_test_svc = df_test[["src_bytes","dst_bytes","count", "srv_count","serror_rate", "srv_serror_rate","same_srv_rate","diff_srv_rate","dst_host_count", "dst_host_srv_count",  "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate", "dst_host_serror_rate","dst_host_serror_rate", "dst_host_srv_serror_rate", "dst_host_rerror_rate"]]
Y_svc = df[["class", "classnum"]]
Y_test_svc = df_test[["class", "classnum"]]

scaler = StandardScaler()
x_train_scaled_svc = scaler.fit_transform(X_svc)
x_test_scaled_svc = scaler.transform(X_test_svc)

x_train_svc, x_test_svc, y_train_svc, y_test_svc = train_test_split(x_train_scaled_svc, Y_svc, test_size=None, random_state=42)

param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

svc_model = SVC()
svc_model.fit(x_train_svc, y_train_svc['classnum'].values.ravel())

accuracy_svc = svc_model.score(x_test_svc, y_test_svc['classnum'].values.ravel())
print(f'Accuracy: {accuracy_svc * 100:.2f}%')

# param_grid = {
#     'C': [0.1, 1, 10],
#     'penalty': ['l1', 'l2'],
#     'loss': ['hinge', 'squared_hinge'],
#     'dual': [False] # Set dual to False if n_samples > n_features
# }

# # Create a SVC instance
# svc_test = SVC(kernel='rbf', C=1e-3, gamma='scale')

# # Create GridSearchCV object
# grid_search = GridSearchCV(svc_test, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# # Fit the grid search to the data
# grid_search.fit(x_train_scaled, y_train_scaled)

#MLP Classifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(x_train)
X_test_scaled = scaler.transform(x_test)

mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50, 50), max_iter=300, random_state=42)
mlp_classifier.fit(X_train_scaled, y_train['class'])

y_pred_mlp = mlp_classifier.predict(X_test_scaled)

classification_report_mlp = classification_report(y_test['class'], y_pred_mlp)
print("Classification Report:")
print(classification_report_mlp)
accuracy_mlp = accuracy_score(y_test['class'], y_pred_mlp)
print(f'Accuracy: {accuracy_mlp * 100:.2f}%')
#Accuracy 99.59% in 2 minutes, 50,25 200
#Accuracy 99.57% in 2 minutes, 64, 32 300
#Accuracy 99.58% in 2 minutes, 100, 50, 1000
#Accuracy 99.63% in 4 minutes, 100, 50, 50, 300

#No need to hyper tune, already extremely accurate